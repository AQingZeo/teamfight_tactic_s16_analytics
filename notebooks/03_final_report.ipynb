{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Final Report\n",
    "\n",
    "Data-driven TFT Set 16 meta summary built from cleaned Riot match data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "- Winners lean into high-cost boards: avg level **9.22 vs 8.49** and avg unit total cost **7.01 vs 5.66**; they field **3.23 five-cost units** per board vs **2.82** overall while using fewer 1-costs.\n",
    "- Core trait anchors for winning boards: **Arcanist (1581)**, **Bilgewater (994)**, **Void (870)**, **Freljord (816)**. Non-fast9 winners cluster around **Void/Freljord/Arcanist**, while fast9 flexes keep **Swain/Taric/Wukong** for utility.\n",
    "- Item edges: most frequent winning items are **Guinsoo's (5054)**, **Thief's Gloves (4329)**, **Adaptive Helm (3233)**; lowest-average-placement items include **Bilgewater Emblem (3.84)**, **Deathblade (3.95)**, **Sterak's (4.00)**.\n",
    "- High-cost carries dominate: **Shyvana** and **Lucian** top 5-cost presence, often paired with **Juggernaut** and **Gunslinger** traits; placement correlates strongest with **avg_unit_total_cost (0.61)** and **level (0.53)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- **Motivation:** Quantify the S16 ranked meta and identify the unit/trait/item patterns that most often appear on top-4 boards.\n",
    "- **Dataset:** 1,604 matches / 1,310 players (12,757 player-match rows) from processed TFT logs; cleaned via schema + range + reference checks.\n",
    "- **Methodology:** Validate raw tables (00), explore distributions and correlations (01), then answer targeted meta questions with saved figures/tables (02).\n",
    "- **Limitations:** No patch-split; assumes reference lookups cover all observed units/traits/items; no MMR control or lobby strength adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "MARKERS = {\"requirements.txt\", \"Projectplan.md\", \".git\"}\n",
    "PROJECT_ROOT = None\n",
    "cwd = Path.cwd()\n",
    "for path in [cwd, *cwd.parents]:\n",
    "    if any((path / m).exists() for m in MARKERS):\n",
    "        PROJECT_ROOT = path\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    PROJECT_ROOT = cwd\n",
    "\n",
    "DATA_PROCESSED = PROJECT_ROOT / 'data' / 'processed'\n",
    "CLEANED_DIR = DATA_PROCESSED / 'cleaned'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'outputs'\n",
    "FIGURES_DIR = OUTPUTS_DIR / 'figures'\n",
    "TABLES_DIR = OUTPUTS_DIR / 'tables'\n",
    "\n",
    "participants = pd.read_csv(CLEANED_DIR / 'participants.csv')\n",
    "traits = pd.read_csv(CLEANED_DIR / 'traits.csv')\n",
    "units = pd.read_csv(CLEANED_DIR / 'units.csv')\n",
    "units_ref = pd.read_csv(DATA_PROCESSED / 'canonical_original' / 'units_s16.csv')\n",
    "unit_cost_map = dict(zip(units_ref['name'], units_ref['cost']))\n",
    "\n",
    "# Preload analysis tables for quick reference\n",
    "cost_dist = pd.read_csv(TABLES_DIR / '02_unit_cost_distribution.csv')\n",
    "unit_pop = pd.read_csv(TABLES_DIR / '02_units_popularity_by_cost.csv')\n",
    "item_freq = pd.read_csv(TABLES_DIR / '02_items_frequency.csv')\n",
    "trait_freq = pd.read_csv(TABLES_DIR / '02_traits_frequency_no_exclusive.csv')\n",
    "winner_traits = pd.read_csv(TABLES_DIR / '02_winner_main_traits.csv')\n",
    "winner_traits_non_fast9 = pd.read_csv(TABLES_DIR / '02_winner_main_traits_non_fast9.csv')\n",
    "fast9_units = pd.read_csv(TABLES_DIR / '02_fast9_non_highcost_units.csv')\n",
    "high_cost_trait = pd.read_csv(TABLES_DIR / '02_high_cost_trait_cofreq.csv')\n",
    "high_cost_no_trait = pd.read_csv(TABLES_DIR / '02_high_cost_units_no_high_traits.csv')\n",
    "\n",
    "winner_boards = participants[participants['placement'] <= 4][['match_id','puuid']]\n",
    "WINNER_BOARD_COUNT = len(winner_boards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview snapshot\n",
    "data_overview = {\n",
    "    'matches': participants['match_id'].nunique(),\n",
    "    'players': participants['puuid'].nunique(),\n",
    "    'player_match_rows': len(participants),\n",
    "    'win_rate_top4': (participants['placement'] <= 4).mean(),\n",
    "    'avg_level': participants['level'].mean(),\n",
    "}\n",
    "pd.DataFrame([data_overview])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Cost distribution for winners\n",
    "- Winners field **3.23 five-cost** units on average vs **2.82** across all players; 1-cost usage drops from **0.49 to 0.44**.\n",
    "- Suggests aggressive leveling/econ pays off more than low-cost reroll in this dataset.\n",
    "\n",
    "![Cost distribution](../outputs/figures/02_cost_distribution_all_vs_winners.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Item popularity and lift\n",
    "- Most common winning items: **Guinsoo's (5054)**, **Thief's Gloves (4329)**, **Adaptive Helm (3233)**.\n",
    "- Lowest-average-placement items (from EDA): **Bilgewater Emblem (3.84)**, **Deathblade (3.95)**, **Sterak's (4.00)**.\n",
    "- Heavy reliance on flexible slam items rather than niche artifacts; emblems appear but are rarer.\n",
    "\n",
    "![Item popularity](../outputs/figures/02_items_popularity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_freq.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Traits popularity and main anchors\n",
    "- Active non-exclusive trait counts (winners) led by **Juggernaut/Arcanist/Defender/Bruiser**; see plot.\n",
    "- Highest active trait per winner: **Arcanist 1581**, **Bilgewater 994**, **Void 870**, **Freljord 816**.\n",
    "- Non-fast9 boards lean **Void/Freljord/Arcanist/Demacia**; fast9 players plug in supportive low-costs like **Swain/Taric/Wukong** while rushing legendaries.\n",
    "\n",
    "![Trait popularity](../outputs/figures/02_traits_popularity.png)\n",
    "\n",
    "![Winner main traits](../outputs/figures/02_winner_main_traits.png)\n",
    "\n",
    "![Winner main traits (non-fast9)](../outputs/figures/02_winner_main_traits_non_fast9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_traits.head(), winner_traits_non_fast9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Popular/powerful non-5/7 cost units\n",
    "- Fast9 players most often keep **Swain (1522)**, **Taric (1054)**, **Wukong (984)** on boards despite pivoting to 5-costs, implying strong utility/CC value.\n",
    "- Non-legendary staples can be highlighted for mid-game stabilization.\n",
    "\n",
    "![Fast9 fillers](../outputs/figures/02_fast9_non_highcost_units.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast9_units.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4b. Fully itemized three-star carries/tanks\n",
    "- Only **5.9%** of winning boards fielded any fully itemized 3-star unit (3 items on a 3-star).\n",
    "- Top capped units by board rate (share of all top-4 boards): **Tryndamere 1.4%**, **Bard 0.6%**, **Neeko 0.45%**, **Nautilus 0.44%**, **Draven 0.39%**.\n",
    "- These are mostly low-cost frontline/utility pieces; fully itemized 3-star carries/tanks are rare in winning comps, implying most wins rely on 2-star legendaries instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully itemized three-star carries/tanks on winner boards\n",
    "item_cols = [c for c in units.columns if c.startswith('item_')]\n",
    "units_win = units.merge(winner_boards, on=['match_id','puuid'], how='inner')\n",
    "three_star_full = units_win.dropna(subset=item_cols)\n",
    "three_star_full = three_star_full[three_star_full['unit_tier'] == 3].copy()\n",
    "three_star_full['unit_cost'] = three_star_full['unit_name'].map(unit_cost_map)\n",
    "\n",
    "three_star_summary = (\n",
    "    three_star_full\n",
    "    .groupby(['unit_name','unit_cost'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "three_star_summary['board_rate'] = three_star_summary['count'] / WINNER_BOARD_COUNT\n",
    "\n",
    "boards_with_any_three_star = three_star_full[['match_id','puuid']].drop_duplicates()\n",
    "three_star_presence_rate = len(boards_with_any_three_star) / WINNER_BOARD_COUNT\n",
    "\n",
    "print(f'Boards with fully itemized 3-star: {len(boards_with_any_three_star)} / {WINNER_BOARD_COUNT} ({three_star_presence_rate:.2%})')\n",
    "three_star_summary.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. High-cost units and trait context\n",
    "- Most frequent high-cost units on winning boards: **Shyvana**, **Lucian**, **Fiddlesticks**, **Azir**, **Kindred**.\n",
    "- Trait co-occurrence shows **Gunslinger (Lucian 3.2k)** and **Juggernaut (Shyvana 2.8k)** as common caps.\n",
    "- A subset of legendary boards win without any high-tier non-exclusive traits active (counts in table below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cost_trait.head(10), high_cost_no_trait.sort_values('count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Winner identifiers (board-level features)\n",
    "- Correlations vs placement_score: **avg_unit_total_cost 0.61**, **level 0.53**, **avg_unit_cost 0.28**, **num_of_items 0.30**. Trait tier average is weakly negative (likely because high-cost comps run fewer trait caps).\n",
    "- Winners average **9.22 level**, **~9 items**, **3.93 unit_cost**, **7.01 total unit cost**; others sit at **8.49 level** and **5.66 total unit cost**.\n",
    "\n",
    "![Correlation matrix](../outputs/figures/01_corr_matrix.png)\n",
    "\n",
    "![Player winrate vs score](../outputs/figures/01_player_winrate_vs_score.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute board-level summary and correlation for transparency\n",
    "item_cols = [c for c in units.columns if c.startswith('item_')]\n",
    "items_long = units[['match_id','puuid'] + item_cols].set_index(['match_id','puuid']).stack(dropna=True).reset_index()\n",
    "items_long.columns = ['match_id','puuid','slot','item']\n",
    "\n",
    "participants_scored = participants.assign(placement_score = 9 - participants['placement'])\n",
    "unit_cost_map = dict(zip(pd.read_csv(DATA_PROCESSED / 'canonical_original' / 'units_s16.csv')['name'],\n",
    "                         pd.read_csv(DATA_PROCESSED / 'canonical_original' / 'units_s16.csv')['cost']))\n",
    "units_cost_df = units.copy()\n",
    "units_cost_df['unit_cost'] = units_cost_df['unit_name'].map(unit_cost_map)\n",
    "units_cost_df['unit_total_cost'] = units_cost_df['unit_cost'] * units_cost_df['unit_tier']\n",
    "\n",
    "unit_counts = units.groupby(['match_id','puuid']).size().rename('units_per_board')\n",
    "items_per_player = items_long.groupby(['match_id','puuid']).size().rename('num_of_items')\n",
    "unit_cost_avg = units_cost_df.groupby(['match_id','puuid'])['unit_cost'].mean().rename('avg_unit_cost')\n",
    "unit_total_cost_avg = units_cost_df.groupby(['match_id','puuid'])['unit_total_cost'].mean().rename('avg_unit_total_cost')\n",
    "avg_trait_tier = traits.groupby(['match_id','puuid'])['tier_current'].mean().rename('avg_trait_tier')\n",
    "\n",
    "player_df = (participants_scored\n",
    "    .merge(unit_counts, on=['match_id','puuid'], how='left')\n",
    "    .merge(items_per_player, on=['match_id','puuid'], how='left')\n",
    "    .merge(unit_cost_avg, on=['match_id','puuid'], how='left')\n",
    "    .merge(unit_total_cost_avg, on=['match_id','puuid'], how='left')\n",
    "    .merge(avg_trait_tier, on=['match_id','puuid'], how='left')\n",
    ")\n",
    "\n",
    "corr_cols = ['placement_score','level','num_of_items','avg_trait_tier','avg_unit_cost','avg_unit_total_cost']\n",
    "correlations = player_df[corr_cols].corr()\n",
    "summary = player_df.assign(is_win_flag = player_df['placement'] <= 4).groupby('is_win_flag').agg({\n",
    "    'placement':'mean',\n",
    "    'level':'mean',\n",
    "    'num_of_items':'mean',\n",
    "    'avg_trait_tier':'mean',\n",
    "    'avg_unit_cost':'mean',\n",
    "    'avg_unit_total_cost':'mean'\n",
    "}).rename(index={True:'winners', False:'others'})\n",
    "summary, correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- **High-cost focus wins:** Rushing 9 and stuffing boards with multiple 5-costs is the clearest differentiator; low-cost reroll is underperforming in this sample.\n",
    "- **Trait anchors vary by econ path:** Fast9 boards anchor on Arcanist/Bilgewater while non-fast9 lean Void/Freljord/Demacia.\n",
    "- **Items reward tempo:** Universal slam items (Guinsoo's, TG, Adaptive Helm) dominate presence; Bilgewater Emblem/Deathblade/Sterak's show best average placements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "- Figures live in `outputs/figures/`; tables in `outputs/tables/`.\n",
    "- Re-run upstream notebooks (`00`, `01`, `02`) to refresh after new data or patches.\n",
    "- Export HTML via `jupyter nbconvert --to html notebooks/03_final_report.ipynb --output ../outputs/report.html`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
