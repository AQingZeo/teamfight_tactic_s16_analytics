{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba887751",
   "metadata": {},
   "source": [
    "# 01 Exploratory Analysis\n",
    "\n",
    "EDA on cleaned TFT match data: quick validation, descriptive stats, distributions, correlations, and early performance patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89345ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MARKERS = {\"requirements.txt\", \"Projectplan.md\", \".git\"}\n",
    "PROJECT_ROOT = None\n",
    "cwd = Path.cwd()\n",
    "for path in [cwd, *cwd.parents]:\n",
    "    if any((path / m).exists() for m in MARKERS):\n",
    "        PROJECT_ROOT = path\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    PROJECT_ROOT = cwd\n",
    "\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "CLEANED_DIR = DATA_PROCESSED / \"cleaned\"\n",
    "CANONICAL_DIR = DATA_PROCESSED / \"canonical_original\"\n",
    "\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\"\n",
    "FIGURES_DIR = OUTPUTS_DIR / \"figures\"\n",
    "for p in [OUTPUTS_DIR, FIGURES_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 180)\n",
    "plt.rcParams.update({\"figure.figsize\": (10, 6), \"figure.dpi\": 120})\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Cleaned dir: {CLEANED_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9578ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load cleaned tables\n",
    "participants = pd.read_csv(CLEANED_DIR / \"participants.csv\")\n",
    "traits = pd.read_csv(CLEANED_DIR / \"traits.csv\")\n",
    "units = pd.read_csv(CLEANED_DIR / \"units.csv\")\n",
    "\n",
    "# Reference lookups from canonical reference files\n",
    "units_ref = pd.read_csv(CANONICAL_DIR / \"units_s16.csv\")\n",
    "traits_ref = pd.read_csv(CANONICAL_DIR / \"traits_s16.csv\")\n",
    "items_ref = pd.read_csv(CANONICAL_DIR / \"items_s16.csv\")\n",
    "\n",
    "valid_units = set(units_ref['name'].dropna())\n",
    "valid_traits = set(traits_ref['name_corrected'].dropna()) if 'name_corrected' in traits_ref.columns else set(traits_ref['name'].dropna())\n",
    "valid_items = set()\n",
    "for col in items_ref.columns:\n",
    "    if col == 'name' or col.startswith('comp'):\n",
    "        valid_items.update(items_ref[col].dropna().astype(str).str.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f496b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten items (retain match_id/puuid for per-player aggregation)\n",
    "item_cols = [c for c in units.columns if c.startswith('item_')]\n",
    "items_long = units[['match_id','puuid','unit_name'] + item_cols].set_index(['match_id','puuid','unit_name']).stack(dropna=True).reset_index()\n",
    "items_long.columns = ['match_id','puuid','unit_name','slot','item']\n",
    "items_long['item'] = items_long['item'].apply(lambda x: x.strip() if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b04003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick validation on cleaned data\n",
    "invalid_units = units[~units['unit_name'].isin(valid_units)]\n",
    "invalid_traits = traits[~traits['trait_id'].isin(valid_traits)]\n",
    "invalid_items_rows = items_long[~items_long['item'].isin(valid_items)]\n",
    "\n",
    "print(f\"Cleaned invalid units: {len(invalid_units)}\")\n",
    "print(f\"Cleaned invalid traits: {len(invalid_traits)}\")\n",
    "print(f\"Cleaned invalid items: {len(invalid_items_rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9339f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Descriptive stats for numeric columns\n",
    "numeric_cols = ['placement', 'level', 'unit_tier']\n",
    "unit_numeric = units[['unit_tier']].copy()\n",
    "unit_numeric['placement'] = units.merge(participants[['match_id','puuid','placement']], on=['match_id','puuid'], how='left')['placement']\n",
    "unit_numeric['level'] = units.merge(participants[['match_id','puuid','level']], on=['match_id','puuid'], how='left')['level']\n",
    "\n",
    "summary_stats = unit_numeric[numeric_cols].describe()\n",
    "summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trait distribution (frequency of active trait appearances)\n",
    "trait_counts = traits['trait_id'].value_counts().reset_index()\n",
    "trait_counts.columns = ['trait_id','count']\n",
    "trait_counts = trait_counts.merge(traits_ref[['name_corrected','rank']], left_on='trait_id', right_on='name_corrected', how='left')\n",
    "trait_counts.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0fd082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Item distribution (flatten item slots)\n",
    "item_counts = items_long['item'].value_counts().reset_index()\n",
    "item_counts.columns = ['item','count']\n",
    "item_counts.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b113313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placement correlation with basic player/unit features\n",
    "unit_counts = units.groupby(['match_id','puuid']).size().rename('units_per_board')\n",
    "item_slots_per_player = items_long.groupby(['match_id','puuid']).size().rename('items_per_board')\n",
    "unit_tier_avg = units.groupby(['match_id','puuid'])['unit_tier'].mean().rename('avg_unit_tier')\n",
    "\n",
    "player_df = participants.merge(unit_counts, on=['match_id','puuid'], how='left')                            .merge(item_slots_per_player, on=['match_id','puuid'], how='left')                            .merge(unit_tier_avg, on=['match_id','puuid'], how='left')\n",
    "\n",
    "corr_cols = ['placement','level','units_per_board','items_per_board','avg_unit_tier']\n",
    "corr_matrix = player_df[corr_cols].corr()\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation matrix')\n",
    "plt.tight_layout()\n",
    "fig_corr_path = FIGURES_DIR / \"01_corr_matrix.png\"\n",
    "plt.savefig(fig_corr_path, bbox_inches='tight')\n",
    "print(f\"Saved correlation heatmap to {fig_corr_path}\")\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Item heatmap: units vs items (top 25 items)\n",
    "item_freq = items_long['item'].value_counts()\n",
    "top_items = item_freq.head(25).index\n",
    "heat_df = (\n",
    "    items_long[items_long['item'].isin(top_items)]\n",
    "    .groupby(['unit_name','item']).size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, max(6, 0.2 * len(heat_df))))\n",
    "sns.heatmap(heat_df, cmap='Blues', cbar_kws={'label': 'count'})\n",
    "plt.title('Item frequency by unit (top 25 items)')\n",
    "plt.xlabel('Item')\n",
    "plt.ylabel('Unit')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "heatmap_path = FIGURES_DIR / \"01_items_heatmap.png\"\n",
    "plt.savefig(heatmap_path, bbox_inches='tight')\n",
    "print(f\"Saved item heatmap to {heatmap_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify interesting patterns (top units/items by lowest avg placement)\n",
    "unit_perf = units.merge(participants[['match_id','puuid','placement']], on=['match_id','puuid'], how='left')\n",
    "unit_perf_stats = unit_perf.groupby('unit_name')['placement'].agg(['count','mean']).rename(columns={'mean':'avg_placement'}).sort_values('avg_placement')\n",
    "print(\"Top 10 units by lowest avg placement:\")\n",
    "print(unit_perf_stats.head(10))\n",
    "\n",
    "items_perf = items_long.merge(participants[['match_id','puuid','placement']], on=['match_id','puuid'], how='left')\n",
    "item_perf_stats = items_perf.groupby('item')['placement'].agg(['count','mean']).rename(columns={'mean':'avg_placement'}).sort_values('avg_placement')\n",
    "print(\"Top 10 items by lowest avg placement:\")\n",
    "print(item_perf_stats.head(10))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
